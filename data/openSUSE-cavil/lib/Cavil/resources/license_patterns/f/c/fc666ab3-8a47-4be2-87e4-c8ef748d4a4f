{"export_restricted":0,"license":"GPL-2.0 WITH Linking-exception","packname":"","patent":0,"pattern":"free software; you can redistribute it and\/or modify\r\n\/\/ it under the terms of the GNU General Public License as published by\r\n\/\/ the Free Software Foundation; either version 2 of the License, or\r\n\/\/ (at your option) any later version.\r\n\/\/\r\n\/\/ This program is distributed in the hope that it will be useful,\r\n\/\/ but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n\/\/ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n\/\/ GNU General Public License for more details.\r\n\/\/\r\n\/\/ You should have received a copy of the GNU General Public License\r\n\/\/ along with this program; if not, write to the Free Software\r\n\/\/ Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA, or visit\r\n\/\/ http:\/\/www.gnu.org\/copyleft\/gpl.html .\r\n\/\/\r\n\/\/ Linking Avisynth statically or dynamically with other modules is making a\r\n\/\/ combined work based on Avisynth.  Thus, the terms and conditions of the GNU\r\n\/\/ General Public License cover the whole combination.\r\n\/\/\r\n\/\/ As a special exception, the copyright holders of Avisynth give you\r\n\/\/ permission to link Avisynth with independent modules that communicate with\r\n\/\/ Avisynth solely through the interfaces defined in avisynth.h, regardless of the license\r\n\/\/ terms of these independent modules, and to copy and distribute the\r\n\/\/ resulting combined work under terms of your choice, provided that\r\n\/\/ every copy of the combined work is accompanied by a complete copy of\r\n\/\/ the source code of Avisynth (the version of Avisynth used to produce the\r\n\/\/ combined work), being distributed under the terms of the GNU General\r\n\/\/ Public License plus this exception.  An independent module is a module\r\n\/\/ which is not derived from or based on Avisynth, such as 3rd-party filters,\r\n\/\/ import and export plugins, or graphical user interfaces.\r\n\r\n\r\n\r\n\r\n\r\n#ifndef __AVISYNTH_H__\r\n#define __AVISYNTH_H__\r\n\r\nenum { AVISYNTH_INTERFACE_VERSION = 3 };\r\n\r\n\r\n\/* Define all types necessary for interfacing with avisynth.dll\r\n   Moved from internal.h *\/\r\n\r\n\/\/ Win32 API macros, notably the types BYTE, DWORD, ULONG, etc. \r\n#include <windef.h>  \r\n\r\n\/\/ COM interface macros\r\n#include <objbase.h>\r\n\r\n\r\n\/\/ Raster types used by VirtualDub & Avisynth\r\n#define in64 (__int64)(unsigned short)\r\ntypedef unsigned long\tPixel;    \/\/ this will break on 64-bit machines!\r\ntypedef unsigned long\tPixel32;\r\ntypedef unsigned char Pixel8;\r\ntypedef long\t\t\tPixCoord;\r\ntypedef\tlong\t\t\tPixDim;\r\ntypedef\tlong\t\t\tPixOffset;\r\n\r\n\r\n\/* Compiler-specific crap *\/\r\n\r\n\/\/ Tell MSVC to stop precompiling here\r\n#ifdef _MSC_VER\r\n  #pragma hdrstop\r\n#endif\r\n\r\n\/\/ Set up debugging macros for MS compilers; for others, step down to the\r\n\/\/ standard <assert.h> interface\r\n#ifdef _MSC_VER\r\n  #include <crtdbg.h>\r\n#else\r\n  #define _RPT0(a,b) ((void)0)\r\n  #define _RPT1(a,b,c) ((void)0)\r\n  #define _RPT2(a,b,c,d) ((void)0)\r\n  #define _RPT3(a,b,c,d,e) ((void)0)\r\n  #define _RPT4(a,b,c,d,e,f) ((void)0)\r\n  \r\n  #define _ASSERTE(x) assert(x)\r\n  #define _ASSERT(x) assert(x)\r\n  #include <assert.h>\r\n#endif\r\n\r\n\r\n\r\n\/\/ I had problems with Premiere wanting 1-byte alignment for its structures,\r\n\/\/ so I now set the Avisynth struct alignment explicitly here.\r\n#pragma pack(push,8)\r\n\r\n#define FRAME_ALIGN 16\r\n\/\/ Default frame alignment is 16 bytes, to help P4, when using SSE2\r\n\r\n\/\/ The VideoInfo struct holds global information about a clip (i.e.\r\n\/\/ information that does not depend on the frame number).  The GetVideoInfo\r\n\/\/ method in IClip returns this struct.\r\n\r\n\/\/ Audio Sample information\r\ntypedef float SFLOAT;\r\n\r\nenum {SAMPLE_INT8  = 1<<0,\r\n        SAMPLE_INT16 = 1<<1, \r\n        SAMPLE_INT24 = 1<<2,    \/\/ Int24 is a very stupid thing to code, but it's supported by some hardware.\r\n        SAMPLE_INT32 = 1<<3,\r\n        SAMPLE_FLOAT = 1<<4};\r\n\r\nenum {\r\n   PLANAR_Y=1<<0,\r\n   PLANAR_U=1<<1,\r\n   PLANAR_V=1<<2,\r\n   PLANAR_ALIGNED=1<<3,\r\n   PLANAR_Y_ALIGNED=PLANAR_Y|PLANAR_ALIGNED,\r\n   PLANAR_U_ALIGNED=PLANAR_U|PLANAR_ALIGNED,\r\n   PLANAR_V_ALIGNED=PLANAR_V|PLANAR_ALIGNED,\r\n  };\r\n\r\nstruct VideoInfo {\r\n  int width, height;    \/\/ width=0 means no video\r\n  unsigned fps_numerator, fps_denominator;\r\n  int num_frames;\r\n  \/\/ This is more extensible than previous versions. More properties can be added seeminglesly.\r\n\r\n  \/\/ Colorspace properties.\r\n  enum {\r\n    CS_BGR = 1<<28,  \r\n    CS_YUV = 1<<29,\r\n    CS_INTERLEAVED = 1<<30,\r\n    CS_PLANAR = 1<<31\r\n  };\r\n\r\n  \/\/ Specific colorformats\r\n  enum { CS_UNKNOWN = 0,\r\n         CS_BGR24 = 1<<0 | CS_BGR | CS_INTERLEAVED,\r\n         CS_BGR32 = 1<<1 | CS_BGR | CS_INTERLEAVED,\r\n         CS_YUY2 = 1<<2 | CS_YUV | CS_INTERLEAVED,\r\n         CS_YV12 = 1<<3 | CS_YUV | CS_PLANAR,  \/\/ y-v-u, planar\r\n         CS_I420 = 1<<4 | CS_YUV | CS_PLANAR,  \/\/ y-u-v, planar\r\n         CS_IYUV = 1<<4 | CS_YUV | CS_PLANAR  \/\/ same as above\r\n         };\r\n  int pixel_type;                \/\/ changed to int as of 2.5\r\n  \r\n\r\n  int audio_samples_per_second;   \/\/ 0 means no audio\r\n  int sample_type;                \/\/ as of 2.5\r\n  __int64 num_audio_samples;      \/\/ changed as of 2.5\r\n  int nchannels;                  \/\/ as of 2.5\r\n\r\n  \/\/ Imagetype properties\r\n\r\n  int image_type;\r\n\r\n  enum {\r\n    IT_BFF = 1<<0,\r\n    IT_TFF = 1<<1,\r\n    IT_FIELDBASED = 1<<2\r\n  };\r\n\r\n  \/\/ useful functions of the above\r\n  bool HasVideo() const { return (width!=0); }\r\n  bool HasAudio() const { return (audio_samples_per_second!=0); }\r\n  bool IsRGB() const { return !!(pixel_type&CS_BGR); }\r\n  bool IsRGB24() const { return (pixel_type&CS_BGR24)==CS_BGR24; } \/\/ Clear out additional properties\r\n  bool IsRGB32() const { return (pixel_type & CS_BGR32) == CS_BGR32 ; }\r\n  bool IsYUV() const { return !!(pixel_type&CS_YUV ); }\r\n  bool IsYUY2() const { return (pixel_type & CS_YUY2) == CS_YUY2; }  \r\n  bool IsYV12() const { return ((pixel_type & CS_YV12) == CS_YV12)||((pixel_type & CS_I420) == CS_I420); }\r\n  bool IsColorSpace(int c_space) const { return ((pixel_type & c_space) == c_space); }\r\n  bool Is(int property) const { return ((pixel_type & property)==property ); }\r\n  bool IsPlanar() const { return !!(pixel_type & CS_PLANAR); }\r\n  bool IsFieldBased() const { return !!(image_type & IT_FIELDBASED); }\r\n  bool IsParityKnown() const { return ((image_type & IT_FIELDBASED)&&(image_type & (IT_BFF|IT_TFF))); }\r\n  bool IsBFF() const { return !!(image_type & IT_BFF); }\r\n  bool IsTFF() const { return !!(image_type & IT_TFF); }\r\n  \r\n  bool IsVPlaneFirst() const {return ((pixel_type & CS_YV12) == CS_YV12); }  \/\/ Don't use this \r\n  int BytesFromPixels(int pixels) const { return pixels * (BitsPerPixel()>>3); }   \/\/ Will not work on planar images, but will return only luma planes\r\n  int RowSize() const { return BytesFromPixels(width); }  \/\/ Also only returns first plane on planar images\r\n  int BMPSize() const { if (IsPlanar()) {int p = height * ((RowSize()+3) & ~3); p+=p>>1; return p;  } return height * ((RowSize()+3) & ~3); }\r\n  __int64 AudioSamplesFromFrames(__int64 frames) const { return (fps_numerator && HasVideo()) ? ((__int64)(frames) * audio_samples_per_second * fps_denominator \/ fps_numerator) : 0; }\r\n  int FramesFromAudioSamples(__int64 samples) const { return (fps_denominator && HasAudio()) ? (int)((samples * (__int64)fps_numerator)\/((__int64)fps_denominator * (__int64)audio_samples_per_second)) : 0; }\r\n  __int64 AudioSamplesFromBytes(__int64 bytes) const { return HasAudio() ? bytes \/ BytesPerAudioSample() : 0; }\r\n  __int64 BytesFromAudioSamples(__int64 samples) const { return samples * BytesPerAudioSample(); }\r\n  int AudioChannels() const { return nchannels; }\r\n  int SampleType() const{ return sample_type;}\r\n  bool IsSampleType(int testtype) const{ return !!(sample_type&testtype);}\r\n  int SamplesPerSecond() const { return audio_samples_per_second; }\r\n  int BytesPerAudioSample() const { return nchannels*BytesPerChannelSample();}\r\n  void SetFieldBased(bool isfieldbased)  { if (isfieldbased) image_type|=IT_FIELDBASED; else  image_type&=~IT_FIELDBASED; }\r\n  void Set(int property)  { image_type|=property; }\r\n  void Clear(int property)  { image_type&=~property; }\r\n\r\n  int BitsPerPixel() const { \r\n    switch (pixel_type) {\r\n      case CS_BGR24:\r\n        return 24;\r\n      case CS_BGR32:\r\n        return 32;\r\n      case CS_YUY2:\r\n        return 16;\r\n      case CS_YV12:\r\n      case CS_I420:\r\n        return 12;\r\n      default:\r\n        return 0;\r\n    }\r\n  }\r\n  int BytesPerChannelSample() const { \r\n    switch (sample_type) {\r\n    case SAMPLE_INT8:\r\n      return sizeof(signed char);\r\n    case SAMPLE_INT16:\r\n      return sizeof(signed short);\r\n    case SAMPLE_INT24:\r\n      return 3;\r\n    case SAMPLE_INT32:\r\n      return sizeof(signed int);\r\n    case SAMPLE_FLOAT:\r\n      return sizeof(SFLOAT);\r\n    default:\r\n      _ASSERTE(\"Sample type not recognized!\");\r\n      return 0;\r\n    }\r\n  }\r\n\r\n  \/\/ useful mutator\r\n  void SetFPS(unsigned numerator, unsigned denominator) {\r\n\tif ((numerator == 0) || (denominator == 0)) {\r\n\t  fps_numerator = 0;\r\n\t  fps_denominator = 1;\r\n\t}\r\n\telse {\r\n\t  unsigned x=numerator, y=denominator;\r\n\t  while (y) {   \/\/ find gcd\r\n\t\tunsigned t = x%y; x = y; y = t;\r\n\t  }\r\n\t  fps_numerator = numerator\/x;\r\n\t  fps_denominator = denominator\/x;\r\n\t}\r\n  }\r\n\r\n  \/\/ Range protected multiply-divide of FPS\r\n  void MulDivFPS(unsigned multiplier, unsigned divisor) {\r\n\tunsigned __int64 numerator   = UInt32x32To64(fps_numerator,   multiplier);\r\n\tunsigned __int64 denominator = UInt32x32To64(fps_denominator, divisor);\r\n\r\n\tunsigned __int64 x=numerator, y=denominator;\r\n\twhile (y) {   \/\/ find gcd\r\n\t  unsigned __int64 t = x%y; x = y; y = t;\r\n\t}\r\n\tnumerator   \/= x; \/\/ normalize\r\n\tdenominator \/= x;\r\n\r\n\tunsigned __int64 temp = numerator | denominator; \/\/ Just looking top bit\r\n\tunsigned u = 0;\r\n#ifdef __GNUC__\r\n\twhile (temp & 0xffffffff80000000LL) { \/\/ or perhaps > 16777216*2\r\n#else\r\n\twhile (temp & 0xffffffff80000000) { \/\/ or perhaps > 16777216*2\r\n#endif\r\n\t  temp = Int64ShrlMod32(temp, 1);\r\n\t  u++;\r\n\t}\r\n\tif (u) { \/\/ Scale to fit\r\n\t  const unsigned round = 1 << (u-1);\r\n\t  SetFPS( (unsigned)Int64ShrlMod32(numerator   + round, u),\r\n\t          (unsigned)Int64ShrlMod32(denominator + round, u) );\r\n\t}\r\n\telse {\r\n\t  fps_numerator   = (unsigned)numerator;\r\n\t  fps_denominator = (unsigned)denominator;\r\n\t}\r\n  }\r\n\r\n  \/\/ Test for same colorspace\r\n  bool IsSameColorspace(const VideoInfo& vi) const {\r\n    if (vi.pixel_type == pixel_type) return TRUE;\r\n    if (IsYV12() && vi.IsYV12()) return TRUE;\r\n    return FALSE;\r\n  }\r\n\r\n};\r\n\r\n\r\n\r\n\r\n\/\/ VideoFrameBuffer holds information about a memory block which is used\r\n\/\/ for video data.  For efficiency, instances of this class are not deleted\r\n\/\/ when the refcount reaches zero; instead they're stored in a linked list\r\n\/\/ to be reused.  The instances are deleted when the corresponding AVS\r\n\/\/ file is closed.\r\n\r\nclass VideoFrameBuffer {\r\n  BYTE* const data;\r\n  const int data_size;\r\n  \/\/ sequence_number is incremented every time the buffer is changed, so\r\n  \/\/ that stale views can tell they're no longer valid.\r\n  long sequence_number;\r\n\r\n  friend class VideoFrame;\r\n  friend class Cache;\r\n  friend class ScriptEnvironment;\r\n  long refcount;\r\n\r\npublic:\r\n  VideoFrameBuffer(int size);\r\n  VideoFrameBuffer();\r\n  ~VideoFrameBuffer();\r\n\r\n  const BYTE* GetReadPtr() const { return data; }\r\n  BYTE* GetWritePtr() { ++sequence_number; return data; }\r\n  int GetDataSize() { return data_size; }\r\n  int GetSequenceNumber() { return sequence_number; }\r\n  int GetRefcount() { return refcount; }\r\n};\r\n\r\n\r\nclass IClip;\r\nclass PClip;\r\nclass PVideoFrame;\r\nclass IScriptEnvironment;\r\nclass AVSValue;\r\n\r\n\r\n\/\/ VideoFrame holds a \"window\" into a VideoFrameBuffer.  Operator new\r\n\/\/ is overloaded to recycle class instances.\r\n\r\nclass VideoFrame {\r\n  int refcount;\r\n  VideoFrameBuffer* const vfb;\r\n  const int offset, pitch, row_size, height, offsetU, offsetV, pitchUV;  \/\/ U&V offsets are from top of picture.\r\n\r\n  friend class PVideoFrame;\r\n  void AddRef() { InterlockedIncrement((long *)&refcount); }\r\n  void Release() { if (refcount==1) InterlockedDecrement(&vfb->refcount); InterlockedDecrement((long *)&refcount); }\r\n\r\n  friend class ScriptEnvironment;\r\n  friend class Cache;\r\n\r\n  VideoFrame(VideoFrameBuffer* _vfb, int _offset, int _pitch, int _row_size, int _height);\r\n  VideoFrame(VideoFrameBuffer* _vfb, int _offset, int _pitch, int _row_size, int _height, int _offsetU, int _offsetV, int _pitchUV);\r\n\r\n  void* operator new(size_t size);\r\n\/\/ TESTME: OFFSET U\/V may be switched to what could be expected from AVI standard!\r\npublic:\r\n  int GetPitch() const { return pitch; }\r\n  int GetPitch(int plane) const { switch (plane) {case PLANAR_U: case PLANAR_V: return pitchUV;} return pitch; }\r\n  int GetRowSize() const { return row_size; }\r\n  int GetRowSize(int plane) const { \r\n    switch (plane) {\r\n    case PLANAR_U: case PLANAR_V: if (pitchUV) return row_size>>1; else return 0;\r\n    case PLANAR_U_ALIGNED: case PLANAR_V_ALIGNED: \r\n      if (pitchUV) { \r\n        int r = ((row_size+FRAME_ALIGN-1)&(~(FRAME_ALIGN-1)) )>>1; \/\/ Aligned rowsize\r\n        if (r<=pitchUV) \r\n          return r; \r\n        return row_size>>1; \r\n      } else return 0;\r\n    case PLANAR_Y_ALIGNED:\r\n      int r = (row_size+FRAME_ALIGN-1)&(~(FRAME_ALIGN-1)); \/\/ Aligned rowsize\r\n      if (r<=pitch) \r\n        return r; \r\n      return row_size;\r\n    }\r\n    return row_size; }\r\n  int GetHeight() const { return height; }\r\n  int GetHeight(int plane) const {  switch (plane) {case PLANAR_U: case PLANAR_V: if (pitchUV) return height>>1; return 0;} return height; }\r\n\r\n  \/\/ generally you shouldn't use these three\r\n  VideoFrameBuffer* GetFrameBuffer() const { return vfb; }\r\n  int GetOffset() const { return offset; }\r\n  int GetOffset(int plane) const { switch (plane) {case PLANAR_U: return offsetU;case PLANAR_V: return offsetV;default: return offset;}; }\r\n\r\n  \/\/ in plugins use env->SubFrame()\r\n  VideoFrame* Subframe(int rel_offset, int new_pitch, int new_row_size, int new_height) const;\r\n  VideoFrame* Subframe(int rel_offset, int new_pitch, int new_row_size, int new_height, int rel_offsetU, int rel_offsetV, int pitchUV) const;\r\n\r\n\r\n  const BYTE* GetReadPtr() const { return vfb->GetReadPtr() + offset; }\r\n  const BYTE* GetReadPtr(int plane) const { return vfb->GetReadPtr() + GetOffset(plane); }\r\n\r\n  bool IsWritable() const { return (refcount == 1 && vfb->refcount == 1); }\r\n\r\n  BYTE* GetWritePtr() const {\r\n    if (vfb->GetRefcount()>1) {\r\n      _ASSERT(FALSE);\r\n      \/\/throw AvisynthError(\"Internal Error - refcount was more than one!\");\r\n    }\r\n    return IsWritable() ? (vfb->GetWritePtr() + offset) : 0;\r\n  }\r\n\r\n  BYTE* GetWritePtr(int plane) const {\r\n    if (plane==PLANAR_Y) {\r\n      if (vfb->GetRefcount()>1) {\r\n        _ASSERT(FALSE);\r\n\/\/        throw AvisynthError(\"Internal Error - refcount was more than one!\");\r\n      }\r\n      return IsWritable() ? vfb->GetWritePtr() + GetOffset(plane) : 0;\r\n    }\r\n    return vfb->data + GetOffset(plane);\r\n  }\r\n\r\n  ~VideoFrame() { InterlockedDecrement(&vfb->refcount); }\r\n};\r\n\r\nenum {\r\n  CACHE_NOTHING=0,\r\n  CACHE_RANGE=1,\r\n  CACHE_ALL=2,\r\n  CACHE_AUDIO=3,\r\n  CACHE_AUDIO_NONE=4\r\n };\r\n\r\n\/\/ Base class for all filters.\r\nclass IClip {\r\n  friend class PClip;\r\n  friend class AVSValue;\r\n  int refcnt;\r\n  void AddRef() { InterlockedIncrement((long *)&refcnt); }\r\n  void Release() { InterlockedDecrement((long *)&refcnt); if (!refcnt) delete this; }\r\npublic:\r\n  IClip() : refcnt(0) {}\r\n\r\n  virtual int __stdcall GetVersion() { return AVISYNTH_INTERFACE_VERSION; }\r\n  \r\n  virtual PVideoFrame __stdcall GetFrame(int n, IScriptEnvironment* env) = 0;\r\n  virtual bool __stdcall GetParity(int n) = 0;  \/\/ return field parity if field_based, else parity of first field in frame\r\n  virtual void __stdcall GetAudio(void* buf, __int64 start, __int64 count, IScriptEnvironment* env) = 0;  \/\/ start and count are in samples\r\n  virtual void __stdcall SetCacheHints(int cachehints,int frame_range) = 0 ;  \/\/ We do not pass cache requests upwards, only to the next filter.\r\n  virtual const VideoInfo& __stdcall GetVideoInfo() = 0;\r\n  virtual __stdcall ~IClip() {}\r\n};\r\n\r\n\r\n\/\/ smart pointer to IClip\r\nclass PClip {\r\n\r\n  IClip* p;\r\n\r\n  IClip* GetPointerWithAddRef() const { if (p) p->AddRef(); return p; }\r\n  friend class AVSValue;\r\n  friend class VideoFrame;\r\n\r\n  void Init(IClip* x) {\r\n    if (x) x->AddRef();\r\n    p=x;\r\n  }\r\n  void Set(IClip* x) {\r\n    if (x) x->AddRef();\r\n    if (p) p->Release();\r\n    p=x;\r\n  }\r\n\r\npublic:\r\n  PClip() { p = 0; }\r\n  PClip(const PClip& x) { Init(x.p); }\r\n  PClip(IClip* x) { Init(x); }\r\n  void operator=(IClip* x) { Set(x); }\r\n  void operator=(const PClip& x) { Set(x.p); }\r\n\r\n  IClip* operator->() const { return p; }\r\n\r\n  \/\/ useful in conditional expressions\r\n  operator void*() const { return p; }\r\n  bool operator!() const { return !p; }\r\n\r\n  ~PClip() { if (p) p->Release(); }\r\n};\r\n\r\n\r\n\/\/ smart pointer to VideoFrame\r\nclass PVideoFrame {\r\n\r\n  VideoFrame* p;\r\n\r\n  void Init(VideoFrame* x) {\r\n    if (x) x->AddRef();\r\n    p=x;\r\n  }\r\n  void Set(VideoFrame* x) {\r\n    if (x) x->AddRef();\r\n    if (p) p->Release();\r\n    p=x;\r\n  }\r\n\r\npublic:\r\n  PVideoFrame() { p = 0; }\r\n  PVideoFrame(const PVideoFrame& x) { Init(x.p); }\r\n  PVideoFrame(VideoFrame* x) { Init(x); }\r\n  void operator=(VideoFrame* x) { Set(x); }\r\n  void operator=(const PVideoFrame& x) { Set(x.p); }\r\n\r\n  VideoFrame* operator->() const { return p; }\r\n\r\n  \/\/ for conditional expressions\r\n  operator void*() const { return p; }\r\n  bool operator!() const { return !p; }\r\n\r\n  ~PVideoFrame() { if (p) p->Release();}\r\n};\r\n\r\n\r\nclass AVSValue {\r\npublic:\r\n\r\n  AVSValue() { type = 'v'; }\r\n  AVSValue(IClip* c) { type = 'c'; clip = c; if (c) c->AddRef(); }\r\n  AVSValue(const PClip& c) { type = 'c'; clip = c.GetPointerWithAddRef(); }\r\n  AVSValue(bool b) { type = 'b'; boolean = b; }\r\n  AVSValue(int i) { type = 'i'; integer = i; }\r\n\/\/  AVSValue(__int64 l) { type = 'l'; longlong = l; }\r\n  AVSValue(float f) { type = 'f'; floating_pt = f; }\r\n  AVSValue(double f) { type = 'f'; floating_pt = float(f); }\r\n  AVSValue(const char* s) { type = 's'; string = s; }\r\n  AVSValue(const AVSValue* a, int size) { type = 'a'; array = a; array_size = size; }\r\n  AVSValue(const AVSValue& v) { Assign(&v, true); }\r\n\r\n  ~AVSValue() { if (IsClip() && clip) clip->Release(); }\r\n  AVSValue& operator=(const AVSValue& v) { Assign(&v, false); return *this; }\r\n\r\n  \/\/ Note that we transparently allow 'int' to be treated as 'float'.\r\n  \/\/ There are no int<->bool conversions, though.\r\n\r\n  bool Defined() const { return type != 'v'; }\r\n  bool IsClip() const { return type == 'c'; }\r\n  bool IsBool() const { return type == 'b'; }\r\n  bool IsInt() const { return type == 'i'; }\r\n\/\/  bool IsLong() const { return (type == 'l'|| type == 'i'); }\r\n  bool IsFloat() const { return type == 'f' || type == 'i'; }\r\n  bool IsString() const { return type == 's'; }\r\n  bool IsArray() const { return type == 'a'; }\r\n\r\n  PClip AsClip() const { _ASSERTE(IsClip()); return IsClip()?clip:0; }\r\n  bool AsBool() const { _ASSERTE(IsBool()); return boolean; }\r\n  int AsInt() const { _ASSERTE(IsInt()); return integer; }   \r\n\/\/  int AsLong() const { _ASSERTE(IsLong()); return longlong; } \r\n  const char* AsString() const { _ASSERTE(IsString()); return IsString()?string:0; }\r\n  double AsFloat() const { _ASSERTE(IsFloat()); return IsInt()?integer:floating_pt; }\r\n\r\n  bool AsBool(bool def) const { _ASSERTE(IsBool()||!Defined()); return IsBool() ? boolean : def; }\r\n  int AsInt(int def) const { _ASSERTE(IsInt()||!Defined()); return IsInt() ? integer : def; }\r\n  double AsFloat(double def) const { _ASSERTE(IsFloat()||!Defined()); return IsInt() ? integer : type=='f' ? floating_pt : def; }\r\n  const char* AsString(const char* def) const { _ASSERTE(IsString()||!Defined()); return IsString() ? string : def; }\r\n\r\n  int ArraySize() const { _ASSERTE(IsArray()); return IsArray()?array_size:1; }\r\n\r\n  const AVSValue& operator[](int index) const {\r\n    _ASSERTE(IsArray() && index>=0 && index<array_size);\r\n    return (IsArray() && index>=0 && index<array_size) ? array[index] : *this;\r\n  }\r\n\r\nprivate:\r\n\r\n  short type;  \/\/ 'a'rray, 'c'lip, 'b'ool, 'i'nt, 'f'loat, 's'tring, 'v'oid, or 'l'ong\r\n  short array_size;\r\n  union {\r\n    IClip* clip;\r\n    bool boolean;\r\n    int integer;\r\n    float floating_pt;\r\n    const char* string;\r\n    const AVSValue* array;\r\n\/\/    __int64 longlong;\r\n  };\r\n\r\n  void Assign(const AVSValue* src, bool init) {\r\n    if (src->IsClip() && src->clip)\r\n      src->clip->AddRef();\r\n    if (!init && IsClip() && clip)\r\n      clip->Release();\r\n    \/\/ make sure this copies the whole struct!\r\n    ((__int32*)this)[0] = ((__int32*)src)[0];\r\n    ((__int32*)this)[1] = ((__int32*)src)[1];\r\n  }\r\n};\r\n\r\n\r\n\/\/ instantiable null filter\r\nclass GenericVideoFilter : public IClip {\r\nprotected:\r\n  PClip child;\r\n  VideoInfo vi;\r\npublic:\r\n  GenericVideoFilter(PClip _child) : child(_child) { vi = child->GetVideoInfo(); }\r\n  PVideoFrame __stdcall GetFrame(int n, IScriptEnvironment* env) { return child->GetFrame(n, env); }\r\n  void __stdcall GetAudio(void* buf, __int64 start, __int64 count, IScriptEnvironment* env) { child->GetAudio(buf, start, count, env); }\r\n  const VideoInfo& __stdcall GetVideoInfo() { return vi; }\r\n  bool __stdcall GetParity(int n) { return child->GetParity(n); }\r\n  void __stdcall SetCacheHints(int cachehints,int frame_range) { } ;  \/\/ We do not pass cache requests upwards, only to the next filter.\r\n};\r\n\r\n\r\nclass AvisynthError \/* exception *\/ {\r\npublic:\r\n  const char* const msg;\r\n  AvisynthError(const char* _msg) : msg(_msg) {}\r\n};\r\n\r\n\r\n\r\n\r\n\/* Helper classes useful to plugin authors *\/\r\n\r\nclass AlignPlanar : public GenericVideoFilter \r\n{\r\npublic:\r\n  AlignPlanar(PClip _clip);\r\n  static PClip Create(PClip clip);\r\n  PVideoFrame __stdcall GetFrame(int n, IScriptEnvironment* env);\r\n};\r\n\r\n\r\n\r\nclass FillBorder : public GenericVideoFilter \r\n{\r\npublic:\r\n  FillBorder(PClip _clip);\r\n  static PClip Create(PClip clip);\r\n  PVideoFrame __stdcall GetFrame(int n, IScriptEnvironment* env);\r\n};\r\n\r\n\r\n\r\nclass ConvertAudio : public GenericVideoFilter \r\n\/**\r\n  * Helper class to convert audio to any format\r\n **\/\r\n{\r\npublic:\r\n  ConvertAudio(PClip _clip, int prefered_format);\r\n  void __stdcall GetAudio(void* buf, __int64 start, __int64 count, IScriptEnvironment* env);\r\n  void __stdcall SetCacheHints(int cachehints,int frame_range);  \/\/ We do pass cache requests upwards, to the cache!\r\n\r\n  static PClip Create(PClip clip, int sample_type, int prefered_type);\r\n  static AVSValue __cdecl Create_float(AVSValue args, void*, IScriptEnvironment*);\r\n  static AVSValue __cdecl Create_32bit(AVSValue args, void*, IScriptEnvironment*);\r\n  static AVSValue __cdecl Create_24bit(AVSValue args, void*, IScriptEnvironment*);\r\n  static AVSValue __cdecl Create_16bit(AVSValue args, void*, IScriptEnvironment*);\r\n  static AVSValue __cdecl Create_8bit(AVSValue args, void*, IScriptEnvironment*);\r\n  virtual ~ConvertAudio();\r\n\r\nprivate:\r\n  void convertToFloat(char* inbuf, float* outbuf, char sample_type, int count);\r\n  void convertToFloat_3DN(char* inbuf, float* outbuf, char sample_type, int count);\r\n  void convertToFloat_SSE(char* inbuf, float* outbuf, char sample_type, int count);\r\n  void convertToFloat_SSE2(char* inbuf, float* outbuf, char sample_type, int count);\r\n  void convertFromFloat(float* inbuf, void* outbuf, char sample_type, int count);\r\n  void convertFromFloat_3DN(float* inbuf, void* outbuf, char sample_type, int count);\r\n  void convertFromFloat_SSE(float* inbuf, void* outbuf, char sample_type, int count);\r\n  void convertFromFloat_SSE2(float* inbuf, void* outbuf, char sample_type, int count);\r\n\r\n  __inline int Saturate_int8(float n);\r\n  __inline short Saturate_int16(float n);\r\n  __inline int Saturate_int24(float n);\r\n  __inline int Saturate_int32(float n);\r\n\r\n  char src_format;\r\n  char dst_format;\r\n  int src_bps;\r\n  char *tempbuffer;\r\n  SFLOAT *floatbuffer;\r\n  int tempbuffer_size;\r\n};\r\n\r\n\r\n\/\/ For GetCPUFlags.  These are backwards-compatible with those in VirtualDub.\r\nenum {                    \r\n                    \/* slowest CPU to support extension *\/\r\n  CPUF_FORCE\t\t\t  = 0x01,   \/\/ N\/A\r\n  CPUF_FPU\t\t\t    = 0x02,   \/\/ 386\/486DX\r\n  CPUF_MMX\t\t\t    = 0x04,   \/\/ P55C, K6, PII\r\n  CPUF_INTEGER_SSE\t= 0x08,\t\t\/\/ PIII, Athlon\r\n  CPUF_SSE\t\t\t    = 0x10,\t\t\/\/ PIII, Athlon XP\/MP\r\n  CPUF_SSE2\t\t\t    = 0x20,\t\t\/\/ PIV, Hammer\r\n  CPUF_3DNOW\t\t\t  = 0x40,   \/\/ K6-2\r\n  CPUF_3DNOW_EXT\t\t= 0x80,\t\t\/\/ Athlon\r\n  CPUF_X86_64       = 0xA0,   \/\/ Hammer (note: equiv. to 3DNow + SSE2, which only Hammer\r\n                              \/\/         will have anyway)\r\n  CPUF_SSE3\t\t= 0x100,\t\t    \/\/ Some P4 & Athlon 64.\r\n};\r\n#define MAX_INT 0x7fffffff\r\n#define MIN_INT -0x7fffffff\r\n\r\n\r\n\r\nclass IScriptEnvironment {\r\npublic:\r\n  virtual __stdcall ~IScriptEnvironment() {}\r\n\r\n  virtual \/*static*\/ long __stdcall GetCPUFlags() = 0;\r\n\r\n  virtual char* __stdcall SaveString(const char* s, int length = -1) = 0;\r\n  virtual char* __stdcall Sprintf(const char* fmt, ...) = 0;\r\n  \/\/ note: val is really a va_list; I hope everyone typedefs va_list to a pointer\r\n  virtual char* __stdcall VSprintf(const char* fmt, void* val) = 0;\r\n\r\n  __declspec(noreturn) virtual void __stdcall ThrowError(const char* fmt, ...) = 0;\r\n\r\n  class NotFound \/*exception*\/ {};  \/\/ thrown by Invoke and GetVar\r\n\r\n  typedef AVSValue (__cdecl *ApplyFunc)(AVSValue args, void* user_data, IScriptEnvironment* env);\r\n\r\n  virtual void __stdcall AddFunction(const char* name, const char* params, ApplyFunc apply, void* user_data) = 0;\r\n  virtual bool __stdcall FunctionExists(const char* name) = 0;\r\n  virtual AVSValue __stdcall Invoke(const char* name, const AVSValue args, const char** arg_names=0) = 0;\r\n\r\n  virtual AVSValue __stdcall GetVar(const char* name) = 0;\r\n  virtual bool __stdcall SetVar(const char* name, const AVSValue& val) = 0;\r\n  virtual bool __stdcall SetGlobalVar(const char* name, const AVSValue& val) = 0;\r\n\r\n  virtual void __stdcall PushContext(int level=0) = 0;\r\n  virtual void __stdcall PopContext() = 0;\r\n\r\n  \/\/ align should be 4 or 8\r\n  virtual PVideoFrame __stdcall NewVideoFrame(const VideoInfo& vi, int align=FRAME_ALIGN) = 0;\r\n\r\n  virtual bool __stdcall MakeWritable(PVideoFrame* pvf) = 0;\r\n\r\n  virtual \/*static*\/ void __stdcall BitBlt(BYTE* dstp, int dst_pitch, const BYTE* srcp, int src_pitch, int row_size, int height) = 0;\r\n\r\n  typedef void (__cdecl *ShutdownFunc)(void* user_data, IScriptEnvironment* env);\r\n  virtual void __stdcall AtExit(ShutdownFunc function, void* user_data) = 0;\r\n\r\n  virtual void __stdcall CheckVersion(int version = AVISYNTH_INTERFACE_VERSION) = 0;\r\n\r\n  virtual PVideoFrame __stdcall Subframe(PVideoFrame src, int rel_offset, int new_pitch, int new_row_size, int new_height) = 0;\r\n\r\n  virtual int __stdcall SetMemoryMax(int mem) = 0;\r\n\r\n  virtual int __stdcall SetWorkingDir(const char * newdir) = 0;\r\n\r\n  virtual void* __stdcall ManageCache(int key, void* data) = 0;\r\n\r\n  enum PlanarChromaAlignmentMode {\r\n\t\t\tPlanarChromaAlignmentOff,\r\n\t\t\tPlanarChromaAlignmentOn,\r\n\t\t\tPlanarChromaAlignmentTest };\r\n\r\n  virtual bool __stdcall PlanarChromaAlignment(PlanarChromaAlignmentMode key) = 0;\r\n\r\n  virtual PVideoFrame __stdcall SubframePlanar(PVideoFrame src, int rel_offset, int new_pitch, int new_row_size, int new_height, int rel_offsetU, int rel_offsetV, int new_pitchUV) = 0;\r\n};\r\n\r\n\r\n\/\/ avisynth.dll exports this; it's a way to use it as a library, without\r\n\/\/ writing an AVS script or without going through AVIFile.\r\nIScriptEnvironment* __stdcall CreateScriptEnvironment(int version = AVISYNTH_INTERFACE_VERSION);\r\n\r\n\r\n#pragma pack(pop)\r\n\r\n#endif \/\/__AVISYNTH_H__","risk":2,"spdx":"","trademark":0,"unique_id":"fc666ab3-8a47-4be2-87e4-c8ef748d4a4f"}